{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain rate field by least-square collocation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute velocity from ELTM coefficients\n",
    "The non-periodic component of east or north displacement, $u$, as a function of the number of days from 2011/04/11, is expressed in terms of the ELTM coefficients:\n",
    "\n",
    "$ u(d) = pd + q + a\\log\\left( 1+\\frac{2(d+21)}{365} \\right) $, where $p$, $q$ and $a$ are 0-, 1- and 10-th coefficients, and 21 is the number of days since the March 11, 2011 Tohoku earthquake until Apritl 1, 2011.\n",
    "\n",
    "Velocity can be derived as \n",
    "$ v(d) = p + \\frac{ka}{1+k(d+21)}$, where $k = 2/365$ (i.e., the inverse of half a year)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "If a pickled data object exists, load and use it as an instance of `GPS_Stations` class named `Korea_GPS_Stations`.\n",
    "The loaded pickle file should contain 55 stations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open( 'Korea_GPS_Stations_coeff_cov_20110401_20161231.p', 'rb' ) as handle:\n",
    "        Korea_GPS_CoeffCov = pickle.load(handle)\n",
    "        # This is a dictionary with 55 stations as keys\n",
    "        # Each item is a dictionary with 4 keys, ecoeff, ecov, ncoeff, ncov.\n",
    "        print(Korea_GPS_CoeffCov['DAEJ']['ecoeff'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Failed to load the pickled data. Generate ELTM coefficients using GPSdata.ipynb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $\\mathbf{M}$ matrix for each point\n",
    "A strain rate tensor ($\\boldsymbol{\\varepsilon}$) at a location is the spatially linear rate of change of velocity at that location. In other words, velocity at a GPS station ($\\mathbf{v}$) can be approximated as the sum of a translation vector, $\\mathbf{t}$, and the product of strain rate and $\\mathbf{X} = \\mathbf{x}^{(i)} - \\mathbf{x}$, where $\\mathbf{x}^{(i)}$ is the position vector of the $i$-th station and $\\mathbf{x}$ is the current location of interest:\n",
    "$ \\mathbf{t} + \\boldsymbol{\\varepsilon} \\mathbf{X} = \\mathbf{v}$.\n",
    "\n",
    "Since we have multiple GPS stations and cannot expect the relationship to hold exactly for all of them, we try to find $\\mathbf{t}$ and $\\boldsymbol{\\varepsilon}$ in the least square sense.\n",
    "$ \\mathbf{t}^{(i)} + \\boldsymbol{\\varepsilon} \\mathbf{X}_{i}^{(i)} = \\mathbf{v}^{(i)}$, where $\\mathbf{X}^{(i)}$ is the position vector of the $i$-th GPS station minus the position vector of a grid point, and $\\mathbf{v}^{(i)}$ is the GPS velocity at the $i$-th station ($i=1,\\ldots,n$).\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & X_{1}^{(1)} & X_{2}^{(1)} & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & X_{1}^{(1)} & X_{2}^{(1)} \\\\\n",
    "1 & 0 & X_{1}^{(2)} & X_{2}^{(2)} & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & X_{1}^{(2)} & X_{2}^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "1 & 0 & X_{1}^{(n)} & X_{2}^{(n)} & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & X_{1}^{(n)} & X_{2}^{(n)}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "t_{1} \\\\\n",
    "t_{2} \\\\\n",
    "\\varepsilon_{11} \\\\\n",
    "\\varepsilon_{12} \\\\\n",
    "\\varepsilon_{21} \\\\\n",
    "\\varepsilon_{22}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "v_{1}^{(1)} \\\\\n",
    "v_{2}^{(1)} \\\\\n",
    "v_{1}^{(2)} \\\\\n",
    "v_{2}^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "v_{1}^{(n)} \\\\\n",
    "v_{2}^{(n)} \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Putting the above relationship in the form of $\\mathbf{M}\\mathbf{x} = \\mathbf{y}$, we invert it for $\\mathbf{x}$ as follows:\n",
    "\n",
    "$\\mathbf{x} = \\left( \\mathbf{M}^{T}\\mathbf{W}\\mathbf{M} \\right)^{-1} \\mathbf{M}^{T}\\mathbf{W} \\mathbf{y}$, \n",
    "where $\\mathbf{W}$ is a diagonal matrix of weighting factors.\n",
    "Among many possible choices for $\\mathbf{W}$, we choose the Gaussian function of distance:\n",
    "\n",
    "$ W = \\exp \\left( -\\frac{(d^{(i)})^{2}}{2\\alpha^{2}} \\right)$, where $d^{(i)}$ is the distance from a location to the $i$-th GPS station and $\\alpha$ is a distance weighting constant of 40 km.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a grid of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngridpts = 51\n",
    "lons = np.linspace(125.0, 131.0, ngridpts)\n",
    "lats = np.linspace(33.0, 38.5, ngridpts)\n",
    "long, latg = np.meshgrid(lons, lats)\n",
    "positions = np.vstack([long.ravel(), latg.ravel()]).transpose()\n",
    "positions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open( 'Korea_GPS_Stations_locations.p', 'rb' ) as handle:\n",
    "        Korea_GPS_Locations = pickle.load(handle)\n",
    "        # This is a dictionary with 55 stations as keys\n",
    "        # Each item is a lenth-2 numpy array.\n",
    "        print(Korea_GPS_Locations['DAEJ'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Failed to load the pickled data. Generate ELTM coefficients using GPSdata.ipynb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for the main tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_M_W( position, Korea_GPS_CoeffCov, Korea_GPS_Locations ):\n",
    "    # Since v vector follows the order of stations stored in CoeffCov,\n",
    "    # we loop over the station keys in CoeffCov to keep the order consistent. \n",
    "    nstations = len(Korea_GPS_CoeffCov.keys())\n",
    "    M = np.zeros((2*nstations, 6))\n",
    "    W = np.eye(2*nstations)\n",
    "    counter = 0\n",
    "    alpha_sq = 4.0e4**2 # (40 km)^2\n",
    "     \n",
    "#     from pyproj import Geod\n",
    "#     geod = Geod(ellps=\"WGS84\")\n",
    "    from pyproj import Proj\n",
    "    if position[0] >= 120.0 and position[0] < 126.0:\n",
    "        utm_zone = 51\n",
    "    elif position[0] >= 126.0 and position[0] < 132.0:\n",
    "        utm_zone = 52\n",
    "    p = Proj(proj='utm',zone=utm_zone, ellps='WGS84', preserve_units=False)\n",
    "    # Convert position lon lat to UTM coordinates\n",
    "    pos_x, pos_y = p(position[0], position[1])\n",
    "    \n",
    "    for station in Korea_GPS_CoeffCov.keys():\n",
    "#         # Attempt 1: Compute geodesic distance from 'position' to station\n",
    "#         lons = [pos_lon, station_lon]\n",
    "#         lats = [pos_lat, station_lat]\n",
    "#         d = geod.line_length(lons, lats)\n",
    "#         # calcalate W value for this station\n",
    "#         Wval = np.exp(-0.5*d**2/alpha_sq)\n",
    "#         # compute along-latitude distance from 'position' to station\n",
    "#         lons = [pos_lon, station_lon]\n",
    "#         lats = [pos_lat, pos_lat]\n",
    "#         X1 = geod.line_length(lons, lats)\n",
    "#         # compute along-longitude distance from 'position' to station\n",
    "#         lons = [pos_lon, pos_lon]\n",
    "#         lats = [pos_lat, station_lat]\n",
    "#         X2 = geod.line_length(lons, lats)\n",
    "\n",
    "        # Convert station lon lat to UTM Coordinates\n",
    "        station_x, station_y = p( Korea_GPS_Locations[station][0], Korea_GPS_Locations[station][1])\n",
    "        # Compute distances using UTM coordinates\n",
    "        X1 = station_x - pos_x\n",
    "        X2 = station_y - pos_y\n",
    "        d2 = X1**2 + X2**2\n",
    "        #print(X1, X2, np.sqrt(d2))\n",
    "        \n",
    "        # Calcalate W value for this station\n",
    "        Wval = np.exp(-0.5*d2/alpha_sq)\n",
    "        \n",
    "        # Populate M and W.\n",
    "        M[2*counter,:] = [1.0, 0.0, X1, X2, 0.0, 0.0]\n",
    "        M[2*counter+1,:] = [0.0, 1.0, 0.0, 0.0, X1, X2]\n",
    "        W[2*counter,2*counter] = Wval\n",
    "        W[2*counter+1,2*counter+1] = Wval\n",
    "        counter = counter + 1\n",
    "        \n",
    "    return M, W\n",
    "\n",
    "def get_eps_omg( M, W, vel_vector ):\n",
    "    # Solve Ax = b\n",
    "    tmpA = np.matmul(np.transpose(M), W)\n",
    "    A = np.matmul( tmpA, M )\n",
    "    b = np.dot(tmpA, vel_vector)\n",
    "    # Take only the velocity gradient and reshape it to 2x2 matrix.\n",
    "    vgrad = np.linalg.solve(A,b)[2:].reshape((2,2))\n",
    "    eps = 0.5*(vgrad+np.transpose(vgrad))\n",
    "    omg = 0.5*(vgrad-np.transpose(vgrad))\n",
    "    return eps, omg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate velocity vector from the ELTM coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocities( Korea_GPS_CoeffCov, d ):\n",
    "    velocities = {}\n",
    "    k = 2.0/365.0 # 1 over 0.5 year.\n",
    "    for station in Korea_GPS_CoeffCov.keys():\n",
    "        p = Korea_GPS_CoeffCov[station]['ecoeff'][0]\n",
    "        a = Korea_GPS_CoeffCov[station]['ecoeff'][10]\n",
    "        ve = p + k*a/(1.0+k*(d+21.0))\n",
    "        p = Korea_GPS_CoeffCov[station]['ncoeff'][0]\n",
    "        a = Korea_GPS_CoeffCov[station]['ncoeff'][10]\n",
    "        vn = p + k*a/(1.0+k*(d+21.0))\n",
    "        velocities[station] = np.array([ve,vn])\n",
    "    return velocities\n",
    "\n",
    "def get_vel_vector( vel ):\n",
    "    vel_vector = np.zeros( 2*len(vel.keys()) )\n",
    "    counter = 0\n",
    "    for s in vel.keys():\n",
    "        vel_vector[2*counter] = vel[s][0]\n",
    "        vel_vector[2*counter+1] = vel[s][1]\n",
    "        counter = counter + 1\n",
    "    return vel_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get strain rates and rotation at every grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vel velctor for April 12, 2011, one day after 04/11.\n",
    "vel = get_velocities( Korea_GPS_CoeffCov, 1.0)\n",
    "print(vel['DAEJ'])\n",
    "\n",
    "vel_vector = get_vel_vector( vel )\n",
    "for position in positions[0:2,:]:\n",
    "    M, W = get_M_W( position, Korea_GPS_CoeffCov, Korea_GPS_Locations )  \n",
    "    eps, omg = get_eps_omg( M, W, vel_vector )\n",
    "    # print(eps, omg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
