{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colorbar, colors\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain rate field by least-square collocation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute velocity from ELTM coefficients\n",
    "The non-periodic component of east or north displacement, $u$, as a function of the number of days from 2011/04/11, is expressed in terms of the 11 ELTM coefficients:\n",
    "\n",
    "$\n",
    "\\mathbf{u}(d) = (p d + q) +\n",
    "\\left( \\mathbf{s}_{a}\\sin(\\omega_{a}d) + \\mathbf{c}_{a}\\cos(\\omega_{a}d) \\right) +\n",
    "\\left( \\mathbf{s}_{h}\\sin(\\omega_{h}d) + \\mathbf{c}_{h}\\cos(\\omega_{h}d) \\right) +\n",
    "a\\log(1+\\Delta d_{m}/T_{m}).\n",
    "$\n",
    "\n",
    "$ u(d) = pd + q + a\\log\\left( 1+\\frac{2(d+21)}{365} \\right) $, where $p$, $q$ and $a$ are 0-, 1- and 10-th coefficients, and 21 is the number of days since the March 11, 2011 Tohoku earthquake until Apritl 1, 2011.\n",
    "\n",
    "Velocity can be derived as \n",
    "$ v(d) = p + \\frac{ka}{1+k(d+21)}$, where $k = 2/365$ (i.e., the inverse of half a year)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "If a pickled data object exists, load and use it as an instance of `GPS_Stations` class named `Korea_GPS_Stations`.\n",
    "The loaded pickle file should contain 55 stations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open( 'Korea_GPS_Stations_coeff_cov_20110401_20161231.p', 'rb' ) as handle:\n",
    "        Korea_GPS_CoeffCov = pickle.load(handle)\n",
    "        # This is a dictionary with 55 stations as keys\n",
    "        # Each item is a dictionary with 4 keys, ecoeff, ecov, ncoeff, ncov.\n",
    "        print(Korea_GPS_CoeffCov['DAEJ']['ecoeff'])\n",
    "except: # FileNotFoundError:\n",
    "    print(\"Failed to load the pickled data. Generate ELTM coefficients using GPSdata.ipynb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $\\mathbf{M}$ matrix for each point\n",
    "A strain rate tensor ($\\boldsymbol{\\varepsilon}$) at a location is the spatially linear rate of change of velocity at that location. In other words, velocity at a GPS station ($\\mathbf{v}$) can be approximated as the sum of a translation vector, $\\mathbf{t}$, and the product of strain rate and $\\mathbf{X} = \\mathbf{x}^{(i)} - \\mathbf{x}$, where $\\mathbf{x}^{(i)}$ is the position vector of the $i$-th station and $\\mathbf{x}$ is the current location of interest:\n",
    "$ \\mathbf{t} + \\boldsymbol{\\varepsilon} \\mathbf{X} = \\mathbf{v}$.\n",
    "\n",
    "Since we have multiple GPS stations and cannot expect the relationship to hold exactly for all of them, we try to find $\\mathbf{t}$ and $\\boldsymbol{\\varepsilon}$ in the least square sense.\n",
    "$ \\mathbf{t}^{(i)} + \\boldsymbol{\\varepsilon} \\mathbf{X}_{i}^{(i)} = \\mathbf{v}^{(i)}$, where $\\mathbf{X}^{(i)}$ is the position vector of the $i$-th GPS station minus the position vector of a grid point, and $\\mathbf{v}^{(i)}$ is the GPS velocity at the $i$-th station ($i=1,\\ldots,n$).\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & X_{1}^{(1)} & X_{2}^{(1)} & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & X_{1}^{(1)} & X_{2}^{(1)} \\\\\n",
    "1 & 0 & X_{1}^{(2)} & X_{2}^{(2)} & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & X_{1}^{(2)} & X_{2}^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "1 & 0 & X_{1}^{(n)} & X_{2}^{(n)} & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & X_{1}^{(n)} & X_{2}^{(n)}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "t_{1} \\\\\n",
    "t_{2} \\\\\n",
    "\\varepsilon_{11} \\\\\n",
    "\\varepsilon_{12} \\\\\n",
    "\\varepsilon_{21} \\\\\n",
    "\\varepsilon_{22}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "v_{1}^{(1)} \\\\\n",
    "v_{2}^{(1)} \\\\\n",
    "v_{1}^{(2)} \\\\\n",
    "v_{2}^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "v_{1}^{(n)} \\\\\n",
    "v_{2}^{(n)} \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Putting the above relationship in the form of $\\mathbf{M}\\mathbf{x} = \\mathbf{y}$, we invert it for $\\mathbf{x}$ as follows:\n",
    "\n",
    "$\\mathbf{x} = \\left( \\mathbf{M}^{T}\\mathbf{W}\\mathbf{M} \\right)^{-1} \\mathbf{M}^{T}\\mathbf{W} \\mathbf{y}$, \n",
    "where $\\mathbf{W}$ is a diagonal matrix of weighting factors.\n",
    "Among many possible choices for $\\mathbf{W}$, we choose the Gaussian function of distance:\n",
    "\n",
    "$ W = \\exp \\left( -\\frac{(d^{(i)})^{2}}{2\\alpha^{2}} \\right)$, where $d^{(i)}$ is the distance from a location to the $i$-th GPS station and $\\alpha$ is a distance weighting constant of 40 km.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a grid of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngridpts = 51\n",
    "lons = np.linspace(125.0, 131.0, ngridpts)\n",
    "lats = np.linspace(33.0, 38.5, ngridpts)\n",
    "long, latg = np.meshgrid(lons, lats)\n",
    "positions = np.vstack([long.ravel(), latg.ravel()]).transpose()\n",
    "positions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open( 'Korea_GPS_Stations_locations.p', 'rb' ) as handle:\n",
    "        Korea_GPS_Locations = pickle.load(handle)\n",
    "        # This is a dictionary with 55 stations as keys\n",
    "        # Each item is a lenth-2 numpy array.\n",
    "        print(Korea_GPS_Locations['DAEJ'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Failed to load the pickled data. Generate ELTM coefficients using GPSdata.ipynb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for the main tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_M_W( position, Korea_GPS_CoeffCov, Korea_GPS_Locations ):\n",
    "    # Since v vector follows the order of stations stored in CoeffCov,\n",
    "    # we loop over the station keys in CoeffCov to keep the order consistent. \n",
    "    nstations = len(Korea_GPS_CoeffCov.keys())\n",
    "    M = np.zeros((2*nstations, 6))\n",
    "    W = np.eye(2*nstations)\n",
    "    counter = 0\n",
    "    alpha_sq = 4.0e4**2 # (40 km)^2\n",
    "     \n",
    "#    from pyproj import Geod\n",
    "#    geod = Geod(ellps=\"WGS84\")\n",
    "    from pyproj import Proj\n",
    "#     if position[0] >= 120.0 and position[0] < 126.0:\n",
    "#         utm_zone = 51\n",
    "#     elif position[0] >= 126.0 and position[0] < 132.0:\n",
    "#         utm_zone = 52\n",
    "    utm_zone = 52\n",
    "    p = Proj(proj='utm',zone=utm_zone, ellps='WGS84', preserve_units=False)\n",
    "    # Convert position lon lat to UTM coordi   nates\n",
    "    pos_x, pos_y = p(position[0], position[1])\n",
    "    \n",
    "    for station in Korea_GPS_CoeffCov.keys():\n",
    "#         # Attempt 1: Compute geodesic distance from 'position' to station\n",
    "#         lons = [pos_lon, station_lon]\n",
    "#         lats = [pos_lat, station_lat]\n",
    "#         d = geod.line_length(lons, lats)\n",
    "#         # calcalate W value for this station\n",
    "#         Wval = np.exp(-0.5*d**2/alpha_sq)\n",
    "#         # compute along-latitude distance from 'position' to station\n",
    "#         lons = [pos_lon, station_lon]\n",
    "#         lats = [pos_lat, pos_lat]\n",
    "#         X1 = geod.line_length(lons, lats)\n",
    "#         # compute along-longitude distance from 'position' to station\n",
    "#         lons = [pos_lon, pos_lon]\n",
    "#         lats = [pos_lat, station_lat]\n",
    "#         X2 = geod.line_length(lons, lats)\n",
    "\n",
    "        # Convert station lon lat to UTM Coordinates\n",
    "        station_x, station_y = p( Korea_GPS_Locations[station][0], Korea_GPS_Locations[station][1])\n",
    "        # Compute distances using UTM coordinates\n",
    "        X1 = station_x - pos_x\n",
    "        X2 = station_y - pos_y\n",
    "        d2 = X1**2 + X2**2\n",
    "        #print(X1, X2, np.sqrt(d2))\n",
    "        \n",
    "        # Calcalate W value for this station\n",
    "        Wval = np.exp(-0.5*d2/alpha_sq)\n",
    "        \n",
    "        # Populate M and W.\n",
    "        M[2*counter,:] = [1.0, 0.0, X1, X2, 0.0, 0.0]\n",
    "        M[2*counter+1,:] = [0.0, 1.0, 0.0, 0.0, X1, X2]\n",
    "        W[2*counter,2*counter] = Wval\n",
    "        W[2*counter+1,2*counter+1] = Wval\n",
    "        counter = counter + 1\n",
    "        \n",
    "    return M, W\n",
    "\n",
    "def get_eps_omega( M, W, vel_vector ):\n",
    "    # Solve Ax = b\n",
    "    tmpA = np.matmul(np.transpose(M), W)\n",
    "    A = np.matmul( tmpA, M )\n",
    "    b = np.dot(tmpA, vel_vector)\n",
    "    # Take only the velocity gradient and reshape it to 2x2 matrix.\n",
    "    vgrad = np.linalg.solve(A,b)[2:].reshape((2,2))\n",
    "    eps = 0.5*(vgrad+np.transpose(vgrad))\n",
    "    omega = 0.5*(vgrad-np.transpose(vgrad))\n",
    "    return eps, omega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate velocity vector from the ELTM coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocities( Korea_GPS_CoeffCov, d ):\n",
    "    velocities = {}\n",
    "    k = 2.0/365.0 # 1 over 0.5 year.\n",
    "    for station in Korea_GPS_CoeffCov.keys():\n",
    "        p = Korea_GPS_CoeffCov[station]['ecoeff'][0]\n",
    "        a = Korea_GPS_CoeffCov[station]['ecoeff'][10]\n",
    "        ve = p + k*a/(1.0+k*(d+21.0))\n",
    "        p = Korea_GPS_CoeffCov[station]['ncoeff'][0]\n",
    "        a = Korea_GPS_CoeffCov[station]['ncoeff'][10]\n",
    "        vn = p + k*a/(1.0+k*(d+21.0))\n",
    "        velocities[station] = np.array([ve,vn])\n",
    "    return velocities\n",
    "\n",
    "def get_vel_vector( vel ):\n",
    "    vel_vector = np.zeros( 2*len(vel.keys()) )\n",
    "    counter = 0\n",
    "    for s in vel.keys():\n",
    "        vel_vector[2*counter] = vel[s][0]\n",
    "        vel_vector[2*counter+1] = vel[s][1]\n",
    "        counter = counter + 1\n",
    "    return vel_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get strain rates and rotation at every grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 5 years, 2011/4/11-2016/4/10\n",
    "nyears = 2\n",
    "vel_vector_annual = np.zeros( (nyears, 2*len(Korea_GPS_CoeffCov.keys())) )\n",
    "\n",
    "for yr in np.arange(nyears):\n",
    "    # get vel velctor for April 12, 2011, one day after 04/11.\n",
    "    if yr == 0:\n",
    "        first_day = 365*yr + 1\n",
    "        last_day = 365*(yr+2)\n",
    "    else:\n",
    "        last_day = 365*(yr+2)\n",
    "    for d in np.arange(first_day, last_day+1):\n",
    "        vel = get_velocities( Korea_GPS_CoeffCov, d)\n",
    "        #rint(vel['DAEJ'])\n",
    "        vel_vector_annual[yr,:] += get_vel_vector( vel )\n",
    "    vel_vector_annual[yr,:] /= 365.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_KINEMATICS = False\n",
    "try: \n",
    "    with open( 'annual_mean_dilation.p', 'rb' ) as handle:\n",
    "        # This is an array of (5, ngridpts, ngridpts)\n",
    "        eps_k_annual = pickle.load(handle)\n",
    "except: # FileNotFoundError:\n",
    "    print(\"Failed to load the pickled dilation rate data.\\n\\\n",
    "    It might be necessary to re-generate kinematic variables.\")\n",
    "    COMPUTE_KINEMATICS = True\n",
    "\n",
    "try: \n",
    "    with open( 'annual_mean_maxshear.p', 'rb' ) as handle:\n",
    "        # This is an array of (5, ngridpts, ngridpts)\n",
    "        eps_max_annual = pickle.load(handle)\n",
    "except: # FileNotFoundError:\n",
    "    print(\"Failed to load the pickled max shear strain rate data.\\n\\\n",
    "    It might be necessary to re-generate kinematic variables.\")\n",
    "    COMPUTE_KINEMATICS = True\n",
    "\n",
    "try: \n",
    "    with open( 'annual_mean_omega.p', 'rb' ) as handle:\n",
    "        # This is an array of (5, ngridpts, ngridpts)\n",
    "        omega_annual = pickle.load(handle)\n",
    "except: # FileNotFoundError:\n",
    "    print(\"Failed to load the pickled rigid-body rotation rate data.\\n\\\n",
    "    It might be necessary to re-generate kinematic variables.\")\n",
    "    COMPUTE_KINEMATICS = True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_KINEMATICS:\n",
    "    eps_k_annual   = np.zeros( (5, ngridpts, ngridpts) )\n",
    "    eps_max_annual = np.zeros( (5, ngridpts, ngridpts) )\n",
    "    omega_annual   = np.zeros( (5, ngridpts, ngridpts) )\n",
    "\n",
    "    for yr in range(nyears):\n",
    "        for i, lat in enumerate(lats):\n",
    "            for j, lon in enumerate(lons):\n",
    "                M, W = get_M_W( np.array([lon, lat]), Korea_GPS_CoeffCov, Korea_GPS_Locations )  \n",
    "                eps, omg = get_eps_omega( M, W, vel_vector_annual[yr,:] )\n",
    "\n",
    "                D, V = scipy.linalg.eigh(eps)\n",
    "                # principal strain rate\n",
    "                eps_p = D\n",
    "                eps_p_map1 = eps_p[0]*V[:,0]\n",
    "                eps_p_map2 = eps_p[1]*V[:,1]\n",
    "                # dilation\n",
    "                eps_k_annual[yr, i, j] = eps_p[0]+eps_p[1]\n",
    "                # max shear strain rate\n",
    "                eps_max_annual[yr, i, j] = abs(eps_p[0]-eps_p[1])\n",
    "                # rigid-body rotation\n",
    "                omega_annual[yr, i, j] = omg[0,1]\n",
    "    #             print(yr, i, j)\n",
    "    with open('annual_mean_dilation.p', 'wb') as handle:\n",
    "        pickle.dump(eps_k_annual, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('annual_mean_maxshear.p', 'wb') as handle:\n",
    "        pickle.dump(eps_max_annual, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('annual_mean_omega.p', 'wb') as handle:\n",
    "        pickle.dump(omega_annual, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    COMPUTE_KINEMATICS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable( long, latg, variable, varname, varsymbol, unit, year, cmap, vmin, vmax, fname='testplot.pdf' ):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(4)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree()) #stamen_terrain.crs)\n",
    "    ax1.set_extent([126, 129.75, 34, 38.5], crs=ccrs.PlateCarree())\n",
    "    # 365.0 is multiplied to convert 1/day to 1/year\n",
    "    plotvar = ax1.contourf(long, latg, variable*365.0, 120, cmap=cmap, \\\n",
    "                 transform=ccrs.PlateCarree(), vmin=vmin, vmax=vmax, zorder=0)\n",
    "    ax1.contour(long, latg, variable*365.0, 30, colors='black', \\\n",
    "                 transform=ccrs.PlateCarree(), vmin=vmin, vmax=vmax, zorder=1)\n",
    "    ax1.add_feature(cfeature.NaturalEarthFeature('physical', 'ocean', '10m', \\\n",
    "                                                 edgecolor='face', facecolor='white'), zorder=2)\n",
    "    # ax1.add_feature(cfeature.OCEAN, facecolor='white', zorder=1)\n",
    "    ax1.add_feature(cfeature.COASTLINE, color='white', linewidth=2, zorder=3)\n",
    "    ax1.set_title(\"{0} ({1:d}.4 - {2:d}.4)\".format(varsymbol, 2011+year-1, 2011+year), fontsize=16)\n",
    "\n",
    "    #get size and extent of axes:\n",
    "    axpos = ax1.get_position()\n",
    "    pos_x = axpos.x0+axpos.width + 0.15*axpos.width\n",
    "    pos_y = axpos.y0\n",
    "    cax_width = 0.05\n",
    "    cax_height = axpos.height\n",
    "    #create new axes where the colorbar should go.\n",
    "    #it should be next to the original axes and have the same height!\n",
    "    pos_cax = fig.add_axes([pos_x,pos_y,cax_width,cax_height])\n",
    "    cbar = colorbar.ColorbarBase(pos_cax, cmap=plt.get_cmap(cmap), \\\n",
    "        norm=colors.Normalize(vmin=vmin, vmax=vmax)) # set min, max of colorbar\n",
    "    cbar.set_label(varname+' ('+varsymbol+', '+unit+')', fontsize=12)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    gl = ax1.gridlines(draw_labels=True, color='gray', zorder=10)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlocator = mticker.FixedLocator([125, 126, 127, 128, 129, 130, 131])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.ylocator = mticker.FixedLocator([34, 35, 36, 37, 38])\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.ylabel_style = {'size': 12, 'color': 'black'}\n",
    "    gl.xlabel_style = {'size': 12, 'color': 'black'}\n",
    "    \n",
    "    fig.savefig(fname, facecolor='white', bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camp: turbo, seismic, coolwarm, rainbow, RdBu\n",
    "#long, latg, variable, varname, varsymbol, year, cmap, vmin, vmax, fname='testplot.pdf' ):\n",
    "for yr in range(1,6):\n",
    "    plot_variable(long, latg, eps_k_annual[yr-1,:,:], \"Dilation rate\", \\\n",
    "                  r'$\\dot{e}$', '1/yr', yr, 'RdBu', \\\n",
    "                  -2e-7, 2e-7, './dilation_yr{0:d}.png'.format(yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camp: turbo, seismic, coolwarm, rainbow, RdBu\n",
    "#long, latg, variable, varname, varsymbol, year, cmap, vmin, vmax, fname='testplot.pdf' ):\n",
    "for yr in range(1,6):\n",
    "    plot_variable(long, latg, eps_max_annual[yr-1,:,:], \"Max. shear strain rate\", \\\n",
    "                  r'$\\dot{\\varepsilon}_{\\mathrm{max}}$', '1/yr', yr, 'rainbow', \\\n",
    "                  0.0, 3e-7, './maxshear_yr{0:d}.png'.format(yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(omega_annual[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camp: turbo, seismic, coolwarm, rainbow, RdBu\n",
    "#long, latg, variable, varname, varsymbol, year, cmap, vmin, vmax, fname='testplot.pdf' ):\n",
    "for yr in range(1,6):\n",
    "    plot_variable(long, latg, omega_annual[yr-1,:,:], \"Rigid-body rotation rate\", \\\n",
    "                  r'$\\dot{\\omega}$', '1/yr', yr, 'RdBu', \\\n",
    "                  -1e-7, 1e-7, './omega_yr{0:d}.png'.format(yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 5\n",
    "fig, axes = plt.subplots(ncols=ncol, nrows=nrow, constrained_layout=True)\n",
    "fig.set_figheight(9)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "for r in range(nrow):\n",
    "    for c in range(ncol):\n",
    "        plotnum = c + ncol*r + 1\n",
    "        ax = axes[r,c] #fig.add_subplot(nrow, ncol, plotnum, projection=ccrs.PlateCarree()) #stamen_terrain.crs)\n",
    "        ax.set_extent([125, 131, 33, 38.5], crs=ccrs.PlateCarree())\n",
    "        ax.set_aspect(1)\n",
    "        ax.coastlines(resolution='10m', linewidth=2)\n",
    "        ax.add_feature(cfeature.OCEAN)\n",
    "        #ax1 = plt.axes(projection=ccrs.PlateCarree())\n",
    "        if r==0:\n",
    "            dilation = ax.contourf(long, latg, eps_k_annual[c,:,:], 60, cmap='Spectral', \\\n",
    "                         transform=ccrs.PlateCarree(), vmin=-0.3e-9, vmax=0.3e-9)\n",
    "            plotvar = r'$\\dot{e}$'\n",
    "            ax.set_title(plotvar+\" {0:d}.4-{1:d}.4\".format(2011+c, 2011+c+1), fontsize=22)\n",
    "            if c == ncol-1:\n",
    "                #get size and extent of axes:\n",
    "                axpos = ax.get_position()\n",
    "                pos_x = axpos.x0 + axpos.width + 0.25*axpos.width\n",
    "                pos_y = axpos.y0\n",
    "                cax_width = 0.02\n",
    "                cax_height = axpos.height\n",
    "                #create new axes where the colorbar should go.\n",
    "                #it should be next to the original axes and have the same height!\n",
    "                pos_cax = fig.add_axes([pos_x,pos_y,cax_width,cax_height])\n",
    "                cbar = plt.colorbar(dilation, cax=pos_cax)\n",
    "                #cbar.set_clim(-0.25e-9,0.25e-9)\n",
    "        else:\n",
    "            emax = ax.contourf(long, latg, eps_max_annual[c,:,:], 60, cmap='jet', #gist_rainbow',\n",
    "                         transform=ccrs.PlateCarree(), vmin=0.0, vmax=0.5e-9)\n",
    "            plotvar = r'$\\dot{\\varepsilon}_{\\mathrm{max}}$'\n",
    "            ax.set_title(plotvar+\" {0:d}.4-{1:d}.4\".format(2011+c, 2011+c+1), fontsize=22)\n",
    "            if c == ncol-1:\n",
    "                #get size and extent of axes:\n",
    "                axpos = ax.get_position()\n",
    "                pos_x = axpos.x0 + axpos.width + 0.25*axpos.width\n",
    "                pos_y = axpos.y0\n",
    "                cax_width = 0.02\n",
    "                cax_height = axpos.height\n",
    "                #create new axes where the colorbar should go.\n",
    "                #it should be next to the original axes and have the same height!\n",
    "                pos_cax = fig.add_axes([pos_x,pos_y,cax_width,cax_height])\n",
    "                cbar = plt.colorbar(emax, cax=pos_cax)\n",
    "                #cbar.set_clim(-0.25e-9,0.25e-9)\n",
    "        \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
