{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS_Stations Class\n",
    "The `GPS_Stations` class is a wrapper for a data dictionary, `{Name: time series data}`. The time series data is an Nx4 ndarray, where N is the number of dates, from 2011/4/1 to 2016/12/31. The 4 columns correspond to date (`datetime` type), east, north and up components (all `float` type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPS_Stations():\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    def add(self, station_name, date, x, y, z):\n",
    "        if station_name in self.data:\n",
    "            # if the station is already in the data dictionary, append a new row of data [date,x,y,z]\n",
    "            self.data.update( {station_name : np.append( self.data[station_name], np.array([date,x,y,z]).reshape(1,4), axis=0 ) } )\n",
    "        else: # if first time adding this station, create a key:data pair.\n",
    "            self.data.update( {station_name : np.array([date,x,y,z]).reshape(1,4)} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "If a pickled data object exists, load and use it as an instance of `GPS_Stations` class named `Korea_GPS_Stations`. If not, i.e., `DATA_EXISTS==False`, read the data files retrived from the repository associated with (Kim et al., Tectonics, 2018) to create and populate an instance of `GPS_Stations` named `Korea_GPS_Stations`. \n",
    "\n",
    "If a pickled `GPS_Stations` data object exists, the first cell will just load it rather than read the coordinate files again. In this case, `DATA_EXISTS` is set to `True` so that the second cell can be skipped.\n",
    "\n",
    "If such a pickled object does not exist (`DATA_EXISTS == False`), the second cell below should be run. Then, the newly created object is pickled for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_EXISTS = False\n",
    "Korea_GPS_Stations = pickle.load( open( \"Korea_GPS_Stations.p\", \"rb\" ) )\n",
    "if Korea_GPS_Stations:\n",
    "    DATA_EXISTS = True\n",
    "    print(\"Data object exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_EXISTS == False:\n",
    "    data_dir = \"GPS Daily Coordinate data (2011 to 2016)/Coordinate\"\n",
    "    Korea_GPS_Stations = GPS_Stations()\n",
    "    years = np.arange(2011,2017)\n",
    "    #print(years)\n",
    "    networks = np.array(['KASI', 'NGII'])\n",
    "    #print(networks)\n",
    "    for yr in years:\n",
    "        for nt in networks:\n",
    "            path = \"./{0:s}/{1}/{2}\".format(data_dir, yr, nt)\n",
    "            #print(path)\n",
    "            for f in os.listdir(path):\n",
    "                fname = \"{0}/{1}\".format(path,f)\n",
    "                fi = open(fname, 'r')\n",
    "                lines = fi.readlines()\n",
    "                date = np.datetime64(lines[2].split()[5]).astype(datetime)\n",
    "                if date == datetime(2012,6,1): # exclude outlier\n",
    "                    continue\n",
    "                linecount = 7\n",
    "                for line in lines[7:]:\n",
    "                    linecount += 1\n",
    "                    fields = line.split()\n",
    "                    fieldnum = len(fields)\n",
    "                    if fieldnum == 6:   # valid data without 'Name' field\n",
    "                        name = fields[1]\n",
    "                        x = float(fields[2])\n",
    "                        y = float(fields[3])\n",
    "                        z = float(fields[4])\n",
    "                    elif fieldnum == 7: # valid data with all the fields filled\n",
    "                        name = fields[1]\n",
    "                        x = float(fields[3])\n",
    "                        y = float(fields[4])\n",
    "                        z = float(fields[5])\n",
    "                    elif fieldnum == 5:   # invalid data with 0 0 0 coordinates\n",
    "                        continue  # move on to the next line\n",
    "                    elif fieldnum <= 1: # bottom blank lines\n",
    "                        break     # stop processing this file\n",
    "                    else:               # None of the above. Abort\n",
    "                        print(\"Problem with line {0} in {1}\".format(linecount, fname))\n",
    "                        break     # stop processing this file\n",
    "                    #print(fname, line)\n",
    "                    Korea_GPS_Stations.add(name, date, x, y, z)\n",
    "                fi.close()\n",
    "    \n",
    "    # delete problematic stations\n",
    "#     problematic_stations = ['TABK', 'GOJE', 'GANH', 'BONH', 'SEJO', 'ULLE', 'SOUL', 'JEOJ', 'HOMI', 'DOKD', 'DONH', 'CHUL', 'DANJ', 'GOSG', 'HCHN', 'SMAN']\n",
    "#     for s in problematic_stations:\n",
    "#         Korea_GPS_Stations.data.pop(s, None)\n",
    "    \n",
    "    # Store the data object for quicker loading later\n",
    "    pickle.dump(Korea_GPS_Stations, open( \"Korea_GPS_Stations.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data are loaded successfully, the data object, `Korea_GPS_Stations`, should contain 75 stations, each of which have a position time series spanning 2011/04/01 to 2016/12/31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the loaded data if desired.\n",
    "scounter = 0\n",
    "for s in Korea_GPS_Stations.data.keys():\n",
    "    scounter += 1\n",
    "    print(scounter, s, Korea_GPS_Stations.data[s][0,0], Korea_GPS_Stations.data[s][-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Data Processing\n",
    "\n",
    "### `get_station_data()`\n",
    "A function that returns date, easting, northing and up for a `station` from `start_datetime` to `end_datetime`.\n",
    "\n",
    "### `plot_selected_station()`\n",
    "A function that plots easting, northing and up for a `selected_station` from `start_datetime` to `end_datetime`.\n",
    "\n",
    "### `eltm()` and `eltm2()`\n",
    "Implementation of Extended Linear Trajectory Model (Bevis and Brown, J.Geodesy, 2014):\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "\\mathbf{x}(t) = \\sum_{i=1}^{np+1} \\mathbf{p}_{i}(t-t_{R})^{i-1} +\n",
    "\\sum_{j=1}^{nJ} \\mathbf{b}_{j}H(t-t_{j}) + \n",
    "\\sum_{k=1}^{nF} \\left( \\mathbf{s}_{k}\\sin(\\omega_{k}t) + \\mathbf{c}_{k}\\cos(\\omega_{k}t) \\right) +\n",
    "\\sum_{m=1}^{nT} \\mathbf{a}_{m}\\log(1+\\Delta t_{m}/T_{m}).\n",
    "\n",
    "\\end{equation}\n",
    "\n",
    "The difference between `eltm` and `eltm2` is that `eltm` takes `days` as `float` while `eltm2` converts `datetime` to `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_data( station, start_datetime=datetime(2011, 4, 1), end_datetime=datetime(2016, 12, 31) ):\n",
    "    \"\"\"\n",
    "    Retrieves a station's data from start_datetime to end_datetime (all inclusive)\n",
    "    and returns 4 arrays of daily time series, date, easting, northing and up.\n",
    "    Note that position components are shifted to be zero on the starting date.\n",
    "    \"\"\"\n",
    "    data = Korea_GPS_Stations.data[station]\n",
    "    start_date = start_datetime.date()\n",
    "    end_date = end_datetime.date()\n",
    "    \n",
    "    datemask = np.logical_and(data[:,0] >= start_date, data[:,0] <= end_date)\n",
    "    start_index = np.where(data[:,0] == start_date)[0]\n",
    "    \n",
    "    date = data[datemask,0]\n",
    "    easting  = data[start_index,1] - data[datemask,   1]\n",
    "    northing = data[datemask,   2] - data[start_index,2]\n",
    "    up       = data[datemask,   3] - data[start_index,3]\n",
    "    #print(data[start_index,2], data[start_index,3])\n",
    "    #print(len(date), len(data[:,0]))\n",
    "    \n",
    "    return date, easting, northing, up\n",
    "\n",
    "def plot_selected_station( selected_station, start_datetime=datetime(2011, 4, 1), \n",
    "                          end_datetime=datetime(2016, 12, 31) ):\n",
    "    \"\"\"\n",
    "    plot the east, north and up position time series for a selected station \n",
    "    from a start date until an end date.\n",
    "    \"\"\"\n",
    "    d, e, n, u = get_station_data(selected_station, start_datetime, end_datetime)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    ax.plot(d, e, 'ro', markersize=2, label=\"east\")\n",
    "    ax.plot(d, n, 'go', markersize=2, label=\"north\")\n",
    "    ax.plot(d, u, 'bo', markersize=2, label=\"up\")\n",
    "    ax.set_title(selected_station)\n",
    "    ax.set_ylabel('Displacement (m)')\n",
    "    ax.set_ylim((-0.1,0.1))\n",
    "    ax.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eltm(days, p, q, sa, ca, sh, ch, a):\n",
    "    from numpy import sin, cos, log   \n",
    "    wa = 2.0*np.pi/365.0  # annual frequency\n",
    "    wh = 4.0*np.pi/365.0  # semi-annual frequency\n",
    "    # Number of days since Tohoku Eq (March 11, 2011) until April 1, 2011.\n",
    "    dd_eq = (datetime(2011, 4, 1)-datetime(2011, 3, 11)) / timedelta(days=1)\n",
    "    dd = 2.0*(days + dd_eq)/365.0 # time scale: half a year\n",
    "    disp = (p*days+q) + sa * sin(wa*days) + ca * cos(wa*days) + sh * sin(wh*days) + ch * cos(wh*days) + a * log(1.0+dd)\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eltm2(day, p, q, sa, ca, sh, ch, a):\n",
    "    days = day.astype(float)\n",
    "    from numpy import sin, cos, log   \n",
    "    wa = 2.0*np.pi/365.0  # annual frequency\n",
    "    wh = 4.0*np.pi/365.0  # semi-annual frequency\n",
    "    # Number of days since Tohoku Eq (March 11, 2011) until April 1, 2011.\n",
    "    dd_eq = 20.0 #(datetime(2011, 4, 1)-datetime(2011, 3, 11)) / timedelta(days=1)\n",
    "    dd = 2.0*(days + dd_eq)/365.0 # time scale: half a year\n",
    "    print(sa, wa, np.sin(days))\n",
    "    disp = (p*days+q) + sa * sin(wa*days) + ca * cos(wa*days) + sh * sin(wh*days) + ch * cos(wh*days) + a * log(1.0+dd)\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station selector widget\n",
    "station_selector = widgets.Select(\n",
    "    options=Korea_GPS_Stations.data.keys(),\n",
    "    value='DAEJ',\n",
    "    rows=10,\n",
    "    description='Select a GPS station:',\n",
    "    disabled=False\n",
    ")\n",
    "display(station_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients for ELTM fitting using 'curve_fit'.\n",
    "selected_station = station_selector.value\n",
    "d, e, n, u = get_station_data(selected_station, datetime(2011, 4, 1), end_datetime=datetime(2016, 9, 11))\n",
    "from scipy.optimize import curve_fit\n",
    "days_float = (d-datetime(2011, 4, 1).date()) / timedelta(days=1)\n",
    "popt, pcov = curve_fit(eltm, days_float, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both data and the fitting function\n",
    "plt.plot(d, e)\n",
    "plt.ylim((-0.05,0.2))\n",
    "plt.plot(d, eltm2(days_float, popt[0], popt[1], popt[2], popt[3], popt[4], popt[5], popt[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position data of a selected station can be plotted with `plot_selected_station` function, too\n",
    "selected_station = station_selector.value\n",
    "plot_selected_station( selected_station, datetime(2016, 1, 1), end_datetime=datetime(2016, 12, 31)  )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt to plot multiple stations on one page.\n",
    "# Needs more work.\n",
    "\n",
    "# count = 0\n",
    "# fignum = 0\n",
    "# panels_per_figure = 6\n",
    "# fig = None\n",
    "# spec2 = None\n",
    "# for s in Korea_GPS_Stations.data.keys():\n",
    "#     panel_id = count % panels_per_figure\n",
    "#     #print(panel_id)\n",
    "#     if panel_id == 0:\n",
    "#         fignum = np.int(count / panels_per_figure)\n",
    "#         print(fignum)\n",
    "#         fig = plt.figure(constrained_layout=True, figsize=(8,10.5))\n",
    "#         spec2 = gridspec.GridSpec(nrows=3, ncols=2,figure=fig)\n",
    "    \n",
    "#     row = np.int(panel_id / 2)\n",
    "#     col = panel_id % 2\n",
    "#     #print(s,fignum,row,col, spec2[row,col])\n",
    "# #     if fignum > 0:\n",
    "# #         break\n",
    "#     ax = fig.add_subplot(spec2[row, col])\n",
    "#     count += 1\n",
    "    \n",
    "#     data = Korea_GPS_Stations.data[s]\n",
    "#     start_date = datetime(2012, 1, 1).date()\n",
    "#     datemask = data[:,0] >= start_date\n",
    "#     start_index = np.where(data[:,0] == start_date)[0]\n",
    "#     print(start_index,datemask)\n",
    "#     date = data[datemask,0]\n",
    "#     easting = data[datemask,1]\n",
    "#     eastref = data[start_index,1]\n",
    "#     northing = data[datemask,2]\n",
    "#     northref = data[start_index,2]\n",
    "#     up = data[datemask,3]\n",
    "#     upref = data[start_index,3]\n",
    "#     ax.set_title(s)\n",
    "#     try:\n",
    "#         ax.plot(date, eastref-easting, 'ro', markersize=2, label=\"east\")\n",
    "#     except ValueError:\n",
    "#         print(\"easting problem: \", s,start_date, date)\n",
    "#     try:\n",
    "#         ax.plot(date, northing-northref, 'go', markersize=2, label=\"north\")\n",
    "#     except ValueError:\n",
    "#         print(\"northing problem: \", s,start_date, date)\n",
    "#     try:\n",
    "#         ax.plot(date, up-upref, 'bo', markersize=2, label=\"up\")\n",
    "#     except ValueError:\n",
    "#         print(\"northing problem: \", s,start_date, date)        \n",
    "#     ax.set_ylabel('Displacement (m)')\n",
    "#     ax.legend(loc=2)\n",
    "    \n",
    "#     if panel_id == 5:\n",
    "#         figname = \"GPS_from_Kim_{0:02d}.png\".format(fignum)\n",
    "#         #print(figname)\n",
    "#         plt.savefig(figname, papertype=\"letter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
