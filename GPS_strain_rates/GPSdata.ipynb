{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS_Stations Class\n",
    "The `GPS_Stations` class is a wrapper for a data dictionary, `{Name: time series data}`. The time series data is an Nx4 ndarray, where N is the number of dates, from 2011/4/1 to 2016/12/31. The 4 columns correspond to date (`datetime` type), east, north and up components (all `float` type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPS_Stations():\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    def add(self, station_name, date, x, y, z):\n",
    "        if station_name in self.data:\n",
    "            # if the station is already in the data dictionary, append a new row of data [date,x,y,z]\n",
    "            self.data.update( {station_name : np.append( self.data[station_name], np.array([date,x,y,z]).reshape(1,4), axis=0 ) } )\n",
    "        else: # if first time adding this station, create a key:data pair.\n",
    "            self.data.update( {station_name : np.array([date,x,y,z]).reshape(1,4)} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "If a pickled data object exists, load and use it as an instance of `GPS_Stations` class named `Korea_GPS_Stations`. If not, i.e., `DATA_EXISTS==False`, read the data files retrived from the repository associated with (Kim et al., Tectonics, 2018) to create and populate an instance of `GPS_Stations` named `Korea_GPS_Stations`. \n",
    "\n",
    "If a pickled `GPS_Stations` data object exists, the first cell will just load it rather than read the coordinate files again. In this case, `DATA_EXISTS` is set to `True` so that the second cell can be skipped.\n",
    "\n",
    "If such a pickled object does not exist (`DATA_EXISTS == False`), the second cell below should be run. Then, the newly created object is pickled for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_EXISTS = False\n",
    "try: \n",
    "    Korea_GPS_Stations = pickle.load( open( \"Korea_GPS_Stations.p\", \"rb\" ) )\n",
    "    if Korea_GPS_Stations:\n",
    "        DATA_EXISTS = True\n",
    "        print(\"Data object exists\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Failed to load the pickled data. Move to the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_EXISTS == False:\n",
    "    data_dir = \"GPS Daily Coordinate data (2011 to 2016)/Coordinate\"\n",
    "    Korea_GPS_Stations = GPS_Stations()\n",
    "    years = np.arange(2011,2017)\n",
    "    #print(years)\n",
    "    networks = np.array(['KASI', 'NGII'])\n",
    "    #print(networks)\n",
    "    for yr in years:\n",
    "        for nt in networks:\n",
    "            path = \"./{0:s}/{1}/{2}\".format(data_dir, yr, nt)\n",
    "            #print(path)\n",
    "            for f in os.listdir(path):\n",
    "                fname = \"{0}/{1}\".format(path,f)\n",
    "                fi = open(fname, 'r')\n",
    "                lines = fi.readlines()\n",
    "                date = np.datetime64(lines[2].split()[5]).astype(datetime)\n",
    "                if date == datetime(2012,6,1): # exclude outlier\n",
    "                    continue\n",
    "                linecount = 7\n",
    "                for line in lines[7:]:\n",
    "                    linecount += 1\n",
    "                    fields = line.split()\n",
    "                    fieldnum = len(fields)\n",
    "                    if fieldnum == 6:   # valid data without 'Name' field\n",
    "                        name = fields[1]\n",
    "                        x = float(fields[2])\n",
    "                        y = float(fields[3])\n",
    "                        z = float(fields[4])\n",
    "                    elif fieldnum == 7: # valid data with all the fields filled\n",
    "                        name = fields[1]\n",
    "                        x = float(fields[3])\n",
    "                        y = float(fields[4])\n",
    "                        z = float(fields[5])\n",
    "                    elif fieldnum == 5:   # invalid data with 0 0 0 coordinates\n",
    "                        continue  # move on to the next line\n",
    "                    elif fieldnum <= 1: # bottom blank lines\n",
    "                        break     # stop processing this file\n",
    "                    else:               # None of the above. Abort\n",
    "                        print(\"Problem with line {0} in {1}\".format(linecount, fname))\n",
    "                        break     # stop processing this file\n",
    "                    #print(fname, line)\n",
    "                    Korea_GPS_Stations.add(name, date, x, y, z)\n",
    "                fi.close()\n",
    "    \n",
    "    # delete problematic stations\n",
    "#     problematic_stations = ['TABK', 'GOJE', 'GANH', 'BONH', 'SEJO', 'ULLE', 'SOUL', 'JEOJ', 'HOMI', 'DOKD', 'DONH', 'CHUL', 'DANJ', 'GOSG', 'HCHN', 'SMAN']\n",
    "#     for s in problematic_stations:\n",
    "#         Korea_GPS_Stations.data.pop(s, None)\n",
    "    \n",
    "    # Store the data object for quicker loading later\n",
    "    pickle.dump(Korea_GPS_Stations, open( \"Korea_GPS_Stations.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data are loaded successfully, the data object, `Korea_GPS_Stations`, should contain 75 stations, each of which have a position time series spanning 2011/04/01 to 2016/12/31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the loaded data if desired.\n",
    "scounter = 0\n",
    "for s in Korea_GPS_Stations.data.keys():\n",
    "    scounter += 1\n",
    "    print(scounter, s, Korea_GPS_Stations.data[s][0,0], Korea_GPS_Stations.data[s][-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Data Processing\n",
    "\n",
    "### `get_station_data()`\n",
    "A function that returns date, easting, northing and up for a `station` from `start_datetime` to `end_datetime`.\n",
    "\n",
    "### `plot_selected_station()`\n",
    "A function that plots easting, northing and up for a `selected_station` from `start_datetime` to `end_datetime`.\n",
    "\n",
    "### `eltm()` and `eltm2()`\n",
    "Implementation of Extended Linear Trajectory Model (Bevis and Brown, J.Geodesy, 2014):\n",
    "\n",
    "$\n",
    "\\mathbf{x}(t) = \\sum_{i=1}^{np+1} \\mathbf{p}_{i}(t-t_{R})^{i-1} +\n",
    "\\sum_{j=1}^{nJ} \\mathbf{b}_{j}H(t-t_{j}) + \n",
    "\\sum_{k=1}^{nF} \\left( \\mathbf{s}_{k}\\sin(\\omega_{k}t) + \\mathbf{c}_{k}\\cos(\\omega_{k}t) \\right) +\n",
    "\\sum_{m=1}^{nT} \\mathbf{a}_{m}\\log(1+\\Delta t_{m}/T_{m}).\n",
    "$\n",
    "\n",
    "\n",
    "The difference between `eltm` and `eltm2` is that `eltm` takes `days` as `float` while `eltm2` converts `datetime` to `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_data( station, start_datetime=datetime(2011, 4, 1), end_datetime=datetime(2016, 12, 31) ):\n",
    "    \"\"\"\n",
    "    Retrieves a station's data from start_datetime to end_datetime (all inclusive)\n",
    "    and returns 4 arrays of daily time series, date, easting, northing and up.\n",
    "    Note that position components are shifted to be zero on the starting date.\n",
    "    \"\"\"\n",
    "    data = Korea_GPS_Stations.data[station]\n",
    "    start_date = start_datetime.date() \n",
    "    if start_date < data[0,0]:\n",
    "        start_date = data[0,0]\n",
    "        print(\"Warning: Start date reset to {0}\".format(start_date))\n",
    "    end_date = end_datetime.date()\n",
    "    if end_date > data[-1,0]:\n",
    "        end_date = data[-1,0]\n",
    "        print(\"Warning: End date reset to {0}\".format(end_date))\n",
    "    print(start_date, data[0,0])\n",
    "    \n",
    "    datemask = np.logical_and(data[:,0] >= start_date, data[:,0] <= end_date)\n",
    "    start_index = np.where(data[:,0] == start_date)[0]\n",
    "    if len(start_index) != 1:\n",
    "        print(start_index)\n",
    "        print(data[0,0], data[-1,0])\n",
    "    \n",
    "    date = data[datemask,0]\n",
    "    easting  = data[start_index,1] - data[datemask,   1]\n",
    "    northing = data[datemask,   2] - data[start_index,2]\n",
    "    up       = data[datemask,   3] - data[start_index,3]\n",
    "    #print(data[start_index,2], data[start_index,3])\n",
    "    #print(len(date), len(data[:,0]))\n",
    "    \n",
    "    return date, easting, northing, up\n",
    "\n",
    "def plot_selected_station( selected_station, start_datetime=datetime(2011, 4, 1), \n",
    "                          end_datetime=datetime(2016, 12, 31) ):\n",
    "    \"\"\"\n",
    "    plot the east, north and up position time series for a selected station \n",
    "    from a start date until an end date.\n",
    "    \"\"\"\n",
    "    d, e, n, u = get_station_data(selected_station, start_datetime, end_datetime)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    ax.plot(d, e, 'ro', markersize=2, label=\"east\")\n",
    "    ax.plot(d, n, 'go', markersize=2, label=\"north\")\n",
    "    ax.plot(d, u, 'bo', markersize=2, label=\"up\")\n",
    "    ax.set_title(selected_station)\n",
    "    ax.set_ylabel('Displacement (m)')\n",
    "    ax.set_ylim((-0.1,0.1))\n",
    "    ax.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eltm(days, p, q, sa, sp, ca, cp, sh, shp, ch, chp, a):\n",
    "    from numpy import sin, cos, log   \n",
    "    wa = 2.0*np.pi/365.0  # annual frequency\n",
    "    wh = 4.0*np.pi/365.0  # semi-annual frequency\n",
    "    # Number of days since Tohoku Eq (March 11, 2011) until April 1, 2011.\n",
    "    dd_eq = (datetime(2011, 4, 1)-datetime(2011, 3, 11)) / timedelta(days=1)\n",
    "    dd = 2.0*(days + dd_eq)/365.0 # time scale: half a year\n",
    "    disp = (p*days+q) + sa * sin(wa*(days-sp)) + ca * cos(wa*(days-cp)) \\\n",
    "            + sh * sin(wh*(days-shp)) + ch * cos(wh*(days-chp)) + a * log(1.0+dd)\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eltm2(day, coeff):\n",
    "    days = day.astype(float)\n",
    "    p, q, sa, sp, ca, cp, sh, shp, ch, chp, a = coeff\n",
    "    from numpy import sin, cos, log   \n",
    "    wa = 2.0*np.pi/365.0  # annual frequency\n",
    "    wh = 4.0*np.pi/365.0  # semi-annual frequency\n",
    "    # Number of days since Tohoku Eq (March 11, 2011) until April 1, 2011.\n",
    "    dd_eq = 20.0 #(datetime(2011, 4, 1)-datetime(2011, 3, 11)) / timedelta(days=1)\n",
    "    dd = 2.0*(days + dd_eq)/365.0 # time scale: half a year\n",
    "    #print(sa, wa, np.sin(days))\n",
    "    disp = (p*days+q) + sa * sin(wa*(days-sp)) + ca * cos(wa*(days-cp)) \\\n",
    "            + sh * sin(wh*(days-shp)) + ch * cos(wh*(days-chp)) + a * log(1.0+dd)\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station selector widget\n",
    "station_selector = widgets.Select(\n",
    "    options=Korea_GPS_Stations.data.keys(),\n",
    "    # NOTE (rclam): seems this has to be manually changed on my end when change GPS station\n",
    "    value='DAEJ', \n",
    "    rows=10,\n",
    "    description='Select a GPS station:',\n",
    "    disabled=False\n",
    ")\n",
    "display(station_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_station = station_selector.value\n",
    "pickled_station = \"./Cleaned_Data/{0}_data_cleaned.p\".format(selected_station)\n",
    "STATION_DATA_EXISTS = False\n",
    "\n",
    "d, e, n, u = get_station_data(selected_station, datetime(2011, 3, 11), end_datetime=datetime(2016, 9, 11))\n",
    "from scipy.optimize import curve_fit\n",
    "days_float = (d-datetime(2011, 4, 1).date()) / timedelta(days=1)\n",
    "popt, pcov = curve_fit(eltm, days_float, e)\n",
    "e_eltm = eltm2(days_float, popt)\n",
    "e_detrended = e - e_eltm\n",
    "\n",
    "# Outlier detect/removal\n",
    "std_e = np.std(e_detrended) # - mean_e)\n",
    "#distance_from_mean = abs(e - mean_e)\n",
    "max_deviations = 3.0\n",
    "not_outlier = e_detrended < (max_deviations * std_e)\n",
    "\n",
    "try: \n",
    "    cleaned_station_data = pickle.load( open( pickled_station, \"rb\" ) )\n",
    "    if cleaned_station_data:\n",
    "        STATION_DATA_EXISTS = True\n",
    "        print(\"Cleaned station data object exists\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Failed to load the pickled data. Move to the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STATION_DATA_EXISTS == False:\n",
    "    \n",
    "#     # Get the coefficients for ELTM fitting using 'curve_fit'.\n",
    "#     from scipy.optimize import curve_fit\n",
    "#     days_float = (d-datetime(2011, 4, 1).date()) / timedelta(days=1)\n",
    "#     popt, pcov = curve_fit(eltm, days_float, e)\n",
    "#     e_eltm = eltm2(days_float, popt)\n",
    "    e_detrended = e - e_eltm\n",
    "\n",
    "    # Outlier detect/removal\n",
    "    #mean_e = np.mean(e_detrended)\n",
    "    std_e = np.std(e_detrended) # - mean_e)\n",
    "    #distance_from_mean = abs(e - mean_e)\n",
    "    max_deviations = 1.0\n",
    "    not_outlier = e_detrended < (max_deviations * std_e)\n",
    "    \n",
    "    # Save cleaned station data\n",
    "    cleaned_station_data = {}\n",
    "    cleaned_station_data['days'] = d[not_outlier]\n",
    "    cleaned_station_data['e'] = e[not_outlier]\n",
    "    cleaned_station_data['n'] = n[not_outlier]\n",
    "    cleaned_station_data['u'] = u[not_outlier]\n",
    "    cleaned_station_data['dfloat'] = days_float[not_outlier].astype('float64')\n",
    "\n",
    "    pickle.dump(cleaned_station_data, \\\n",
    "                open( \"./Cleaned_Data/{0}_data_cleaned.p\".format(selected_station), \"wb\" ) )\n",
    "    \n",
    "if cleaned_station_data:\n",
    "    if STATION_DATA_EXISTS:\n",
    "        print(\"Cleaned station data successfully loaded.\")\n",
    "    else:\n",
    "        print(\"Cleaned station data successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "for ax in axs:\n",
    "    for axis in ['top', 'bottom', 'left', 'right']:\n",
    "        ax.spines[axis].set_linewidth(2.0)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(9)\n",
    "\n",
    "axs[0].plot(d,e)\n",
    "axs[0].tick_params(direction='out', length=6, width=2, labelsize=14)\n",
    "axs[0].tick_params(which='minor', direction='out', length=4, width=2)\n",
    "axs[0].set_title(\"{0}: Raw data\".format(selected_station))\n",
    "axs[0].set_xlabel('Time', size=16)\n",
    "axs[0].set_ylabel('Easting (m)', size=16)\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot both data and the fitting function\n",
    "from numpy import log\n",
    "axs[1].plot(cleaned_station_data['days'], cleaned_station_data['e'],\\\n",
    "            marker='.', markerfacecolor='gray', linestyle='none', alpha=1.0, label='Cleaned data')\n",
    "axs[1].set_ylim((-0.05,0.2))\n",
    "axs[1].plot(cleaned_station_data['days'], e_eltm[not_outlier], color='tab:red',\\\n",
    "        linewidth=2, label='ELTM')\n",
    "axs[1].plot(cleaned_station_data['days'], popt[0]*cleaned_station_data['dfloat'] + popt[1], \\\n",
    "         color='tab:green', linewidth=2, label='linear')\n",
    "axs[1].plot(cleaned_station_data['days'], popt[0]*cleaned_station_data['dfloat'] + popt[1] \\\n",
    "         + popt[10]*log(1.0+2.0*(cleaned_station_data['dfloat'] + 20.0)/365.0),\\\n",
    "        color='tab:orange', linewidth=2, label='linear+log')\n",
    "axs[1].tick_params(direction='out', length=6, width=2, labelsize=14)\n",
    "axs[1].tick_params(which='minor', direction='out', length=4, width=2)\n",
    "axs[1].set_title(\"{0}: Cleaned data and ELTM\".format(selected_station))\n",
    "axs[1].set_xlabel('Time', size=16)\n",
    "axs[1].set_ylabel('Easting (m)', size=16)\n",
    "legend = axs[1].legend(loc=4, fontsize=12)\n",
    "legend.get_frame().set_linewidth(2)\n",
    "axs[1].grid()\n",
    "\n",
    "plt.savefig(\"./ELTM_plots/Cleaned_ELTM_{0}.pdf\".format(selected_station))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data > 1 $\\sigma$ from the detrended filtered out.\n",
    "- Notes on 21 problematic stations\n",
    "    - WPWN: Station unidentified and location unknown\n",
    "    - HOMI: Is the \"coseismic slip\" real?\n",
    "    - JEOJ: Is the \"coseismic slip\" real?\n",
    "    - MARA: Is the \"coseismic slip\" real?\n",
    "    - ULLE: Is the \"coseismic slip\" real?\n",
    "    - SOUL: Data corrupted after early 2015?\n",
    "    - TABK: Data corrupted after early 2012?\n",
    "    - DOKD: Data corrupted?\n",
    "    - SEJO: Data length shorter than others.\n",
    "    - GOJE: Data length shorter than others.\n",
    "    - KUSN: Data length shorter than others.\n",
    "    - YODK: Data length shorter than others.\n",
    "    - JIND: Data length shorter than others.\n",
    "    - YOIN: Data length shorter than others.\n",
    "    - SEJN: Data length shorter than others.\n",
    "    - GANH: Data length shorter than others.\n",
    "    - BONH: Data length shorter than others.\n",
    "    - DONH: Data length shorter than others.\n",
    "    - CHUL: Data length shorter than others.\n",
    "    - DANJ: Data length shorter than others.\n",
    "    - GOSG: Data length shorter than others.\n",
    "    - HCHN: Data length shorter than others.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_stations = np.array(['HOMI','JEOJ','MARA','ULLE','SOUL','TABK','DOKD','SEJO',\\\n",
    "                                'GOJE','KUSN','YODK','JIND','YOIN','SEJN','GANH','BONH',\\\n",
    "                                'DONH','CHUL','DANJ','GOSG','HCHN','WPWN'])\n",
    "for station in problematic_stations:\n",
    "    try:\n",
    "        Korea_GPS_Stations.data.pop(station)\n",
    "    except KeyError:\n",
    "        continue\n",
    "# Save 54 stations that has data from 2011/04/11 to 2016/09/11.\n",
    "pickle.dump(Korea_GPS_Stations, open( \"Korea_GPS_Stations_20110401_20160911.p\", \"wb\" ) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "station_locations = pd.read_excel (r'GPS_station_locations.xlsx')\n",
    "print (station_locations['Station'])\n",
    "\n",
    "#Korea_GPS_Stations.data['DAEJ']\n",
    "#for station in df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.set_extent([125,130, 33, 39], crs=ccrs.PlateCarree())\n",
    "#for ax_i in axs:\n",
    "#    for axis in ['top', 'bottom', 'left', 'right']:\n",
    "#        ax_i.spines[axis].set_linewidth(2.0)\n",
    "#ax.tick_params(direction='out', length=6, width=2, labelsize=14)\n",
    "#ax.tick_params(which='minor', direction='out', length=4, width=2)\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.ticker as mticker\n",
    "ax.coastlines(resolution='10m')\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "gl.xlocator = mticker.FixedLocator([125, 126, 127, 128, 129, 130])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.ylabel_style = {'size': 17, 'color': 'black'}\n",
    "gl.xlabel_style = {'size': 17, 'color': 'black'}\n",
    "#gl.xlabel_style = {'color': 'red', 'weight': 'bold'}\n",
    "\n",
    "# ax.add_feature(cfeature.LAND)\n",
    "# ax.add_feature(cfeature.OCEAN)\n",
    "# ax.add_feature(cfeature.COASTLINE)\n",
    "# ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "counter = 0\n",
    "for station in Korea_GPS_Stations.data.keys():\n",
    "    loc_ind = station_locations.index[station_locations['Station'] == station].to_list()\n",
    "    if len(loc_ind) == 1:\n",
    "        counter = counter + 1\n",
    "        #print(\"{0} Found index for {1}: {2}\".format(counter, station, loc_ind[0]))        \n",
    "    else:\n",
    "        #print(\"Location not found: {0}\".format(station))\n",
    "        continue\n",
    "    lon = station_locations.at[loc_ind[0], 'Longitude (deg)']\n",
    "    lat = station_locations.at[loc_ind[0], 'Latitude (deg)']\n",
    "    ax.plot(lon, lat, marker='o', color='red', markersize=12,\n",
    "            alpha=0.7, transform=ccrs.PlateCarree())\n",
    "    ax.text(lon, lat+0.1, station,\n",
    "            verticalalignment='center', horizontalalignment='right',\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            bbox=dict(facecolor='sandybrown', alpha=0.5, boxstyle='round'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
